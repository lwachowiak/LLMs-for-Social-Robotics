# Are Large Language Models Aligned with People's Social Intuitions for Human–Robot Interactions?

In this paper, we investigate the alignment between LLMs and people in experiments from social HRI.

<img src="https://github.com/lwachowiak/LLMs-for-Social-Robotics/blob/main/overview.png" width="600" />


## [arXiv](https://arxiv.org/abs/2403.05701v1) / [IROS](https://ieeexplore.ieee.org/document/10801325)
```
@INPROCEEDINGS{wachowiak2024large,
  author={Wachowiak, Lennart and Coles, Andrew and Celiktutan, Oya and Canal, Gerard},
  booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Are Large Language Models Aligned with People’s Social Intuitions for Human–Robot Interactions?}, 
  year={2024},
  pages={2520-2527},
  doi={10.1109/IROS58592.2024.10801325}
}
```

## Results 
Correlations are highest with GPT-4, as shown in the following scatterplots:

**Experiment 1**
![Correlations for Exp1 with GPT-4](https://github.com/lwachowiak/LLMs-for-Social-Robotics/blob/main/code/Experiment_1/plots/gpt_4_correlations.png)

**Experiment 2**
![Correlations for Exp1 with GPT-4](https://github.com/lwachowiak/LLMs-for-Social-Robotics/blob/main/code/Experiment_2/plots/gpt_4_avg_correlations.png)
![Correlations for Exp1 with GPT-4](https://github.com/lwachowiak/LLMs-for-Social-Robotics/blob/main/code/Experiment_2/plots/gpt_4_diff_correlations.png)


For full results, refer to the paper. Scatterplots for other models can be found [here](https://github.com/lwachowiak/LLMs-for-Social-Robotics/tree/main/code/Experiment_1/plots) for Experiment 1 and [here](https://github.com/lwachowiak/LLMs-for-Social-Robotics/tree/main/code/Experiment_2/plots) for Experiment 2. 

## Video Stimuli 
To get the video stimuli, use the following GitHub: https://github.com/lwachowiak/HRI-Video-Survey-on-Preferred-Robot-Responses 

